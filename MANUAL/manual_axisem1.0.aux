\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Authors, contributors \& copyright}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Preliminaries}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Software and hardware environment}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}References}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Overview}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Minimalist approach}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}General remarks on the codes}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}General workflow}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Technical ingredients}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Mesher}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Mesher installation and compilation}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Mesher input}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textit  {{\tt  inparam\_mesh}: defines all relevant parameters, mostly self-explanatory. }}}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Running the mesher}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Changing the background model}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Mesher computational aspects}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Mesher code structure and components}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7}Mesher output}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.8}Mesher Post-processing/quality control }{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.9}Cautions}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.10}Issues}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.11}Mesher To Do}{13}}
\newlabel{fig:mesh_vp}{{4.8}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \textit  {The elemental mesh (blue lines) for IASP91 at 20 seconds superimposed on the $v_p$ velocity. The plot is derived straight from the file {\tt  mesh\_vp.vtk} produced by the mesher. Zoom sections of the central region and crust/upper mantle are added to highlight the topological features.}}}{14}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Solver}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Solver installation and compilation}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Solver input}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \textit  {{\tt  inparam}: defines all relevant parameters, mostly self-explanatory. }}}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \textit  {{\tt  sourceparams.dat}: Specifies source properties using its own format.}}}{18}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \textit  {{\tt  CMTSOLUTION}: Specifies source properties using the Harvard CMT format. Note that the source-time function is added as the first string in the first line, if none is added, then a Dirac delta distribution is assumed.}}}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \textit  {The smooth source time functions for a period of $T_0=20$s. Note the shifted center for each function ($1.5 T_0$ for all except the wiggly wavelet which is shifted by $300s$). The amplitude includes the scalar moment of the source. }}}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces \textit  {Power spectra of the source time functions from the previous Figure.}}}{21}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Adding lateral heterogeneities}{22}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces \textit  {{\tt  inparam\_hetero}: defines the region of lateral heterogeneities and medium variations.}}}{22}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Running the solver}{22}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Solver computational aspects}{23}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces  \textit  {RAM and CPU requirements for simulations at dominant period 10s, PREM}.}}{23}}
\newlabel{apptable:matrix_op}{{1}{23}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6}Solver code structure}{23}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7}Choice of appropriate time schemes}{24}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.8}At run-time}{24}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.9}Solver output}{24}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.10}Cautions}{25}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.11}Issues}{25}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.12}Solver To Do}{26}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Post processing}{27}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces \textit  {{\tt  param\_post\_processing}: Automatically generated input file for post processing.}}}{27}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces \textit  {{\tt  param\_snaps}: Input for {\tt  post\_processing.f90} created by the Solver. These parameters control the geometry of the slices/surfaces of the 3D sphere upon which wavefields are projected. }}}{28}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Post processing output}{29}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces \textit  {The kml file output from post processing. It contains the rotated, original source-receiver geometry. Mouse-clicks on earthquake location provide source information, mouse-clicks on receiver pins receiver location information and graphics of the local seismograms.}}}{29}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Example workflows}{30}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Kernel calculations}{30}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}Kerner installation and compilation}{30}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2}Running the Kerner}{30}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.3}Kerner input}{30}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.4}Kerner computational aspects}{30}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.5}Kerner code structure}{30}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.6}Kerner output}{30}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.7}Kerner post-processing}{30}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.8}Kerner To Do}{30}}
\citation{nissen+:07a}
\citation{nissen+:07a}
\citation{KoTr02a,manu04}
\citation{nissen+:07a}
\@writefile{toc}{\contentsline {section}{\numberline {9}Theoretical foundations}{31}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1}Elastodynamic equations of motion: weak form}{31}}
\newlabel{eq:weak1}{{1}{31}}
\newlabel{eq:weak2}{{2}{31}}
\newlabel{eq:weak3}{{3}{31}}
\newlabel{eq:potential}{{4}{31}}
\newlabel{eq:fluid_waveequation}{{5}{31}}
\citation{nissen+:07a}
\citation{prem}
\citation{nissen+:07b}
\citation{manu03}
\citation{KaeserDumbser:05}
\citation{KoTr02a}
\citation{nissen+:07b}
\newlabel{eq:ax_bc_mo}{{8}{32}}
\newlabel{eq:ax_bc_di}{{8}{32}}
\newlabel{eq:ax_bc_qu}{{8}{32}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2}Meshing}{32}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces \textbf  {Left:} The semicircular, solid-fluid domain $\Omega =\Omega ^{\rm  s} + \Omega ^{\rm  f}$ discretized for the PREM background model using quadrilateral elements $\Omega _e$ for dominant source period $T_0=20\tmspace  +\thinmuskip {.1667em} \textrm  {s}$. Note that all discontinuities are honored and several conforming coarsening levels are included to maintain a relatively constant resolution throughout the domain. \textbf  {Top right:} Enlargement of the crust for one (right) and two (left) crustal layers, and the upper mantle, including one mesh coarsening region. Note the variable vertical spacing due to discontinuities. \textbf  {Bottom right:} The central region for two resolutions. To circumvent the singularity at the center, we apply the following analytical expressions to reshape rectangular elements: $\left |{x}\right |^p+\left |{y}\right |^p=\left |{r}\right |^p$, $x=s+z,\tmspace  +\thinmuskip {.1667em}y=s-z,\tmspace  +\thinmuskip {.1667em}1\le p \le 2$. This guarantees an easy handle on grid spacing which varies maximally at the outermost, deformed elements of this central region and hence controls stability and resolution.}}{33}}
\newlabel{img:prem_mesh}{{12}{33}}
\citation{nissen+:07b}
\citation{Ampuero+:07}
\newlabel{eq:period}{{9}{34}}
\newlabel{eq:timestep}{{10}{34}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.2.1}The background-model based spherical mesh}{34}}
\citation{nissen+:07b}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Elementally minimal and maximal characteristic lead times scaled by the time step and Courant number, $\tau _{\rm  p,s} {\EuScript  C}^0/\Delta {t}$ in the spherical part of the model space as a function of radius. We depict PREM meshes for source periods $T_0=10\tmspace  +\thinmuskip {.1667em}\textrm  {s}$ (left) and $T_0=20\tmspace  +\thinmuskip {.1667em} \textrm  {s}$ (right). The vertical line to the left denotes unity, i.e. minimal possible $\qopname  \relax m{min}[\tau _{\rm  p}]$ due to the definition of $\Delta {t}$ in eq.~(\ref  {eq:timestep}), and the vertical line to the right the corresponding maximal value given by the relationship for the source period, eq.~(\ref  {eq:period}), i.e. $T_0 {\EuScript  C}^0/(n^0_{\Lambda }\Delta {t})$.}}{35}}
\newlabel{img:char_time}{{13}{35}}
\citation{nissen+:07b}
\citation{nissen+:07b}
\citation{KoTr02a}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Characteristic lead times and time steps for various mesh resolutions and Courant number ${\EuScript  C}^0=0.6$ and $n_\Lambda ^0=6$.}}{36}}
\newlabel{table:char_time}{{2}{36}}
\citation{manuthesis}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Local temporal oversampling in terms of period and time step for the mesh down to $10\tmspace  +\thinmuskip {.1667em} \textrm  {s}$. Unity would be equivalent to the ideal case of no variation for the characteristic lead time $\tau $ whatsoever, impossible for any elastic medium. A more realistic aim, the empty circles to the left depict the ratio $\tau _{\rm  p}/\tau _{\rm  s}$ which represents the limiting case of ideal meshing for the given background model \textit  {and} the inevitable grid spacing variation due to the polynomial basis of Gauss-Lobatto-Legendre points \citep  {nissen+:07b}, i.e. with no oversampling due to suboptimal meshing. The vertical line to the right is the constant ratio $(T_0/\Delta {t})({\EuScript  C}^0/n^0_\Lambda )$, i.e. the global worst case scenario after which these parameters have been chosen. }}{37}}
\newlabel{img:spacing_ratios}{{14}{37}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.2.2}The central region}{37}}
\newlabel{section:central_region}{{9.2.2}{37}}
\newlabel{eq:central}{{13}{37}}
\citation{Ampuero+:07}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Numerical parameters in the central region for the PREM mesh down to $10\tmspace  +\thinmuskip {.1667em} {\rm  s}$. \textbf  {Left:} Number of points per $S$ wavelength scaled by the minimal value $n_\Lambda ^0=4$. The fact that we need to resolve $S$ waves in the inner core as opposed to outer core results in a drastic minimal velocity drop across the ICB and accordingly grid densification. \textbf  {Right:} Local oversampling ratio, i.e. the period $T_0$ versus characteristic lead spacing time $\tau _{\rm  p}$. The colorbar bounds represent the extremal characteristic lead times in the spherical domain above.}}{38}}
\newlabel{img:central}{{15}{38}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.2.3}Mesh scaling and computational cost}{38}}
\citation{Ampuero+:07}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Computational cost of the mesh. \textbf  {Left:} Instantaneous cost, i.e. the size of the mesh. \textbf  {Right:} Extrapolation cost, i.e. the number of time steps. Both functions are constructed in a non-dimensionalized fashion such that they cancel out resolution dependencies when plotted as a function of the source period $T_0$.}}{39}}
\newlabel{img:cost}{{16}{39}}
\newlabel{eq:abscost_homo}{{14}{39}}
\newlabel{eq:instcost}{{15}{39}}
\newlabel{eq:extrapolcost}{{16}{39}}
\citation{TufoFischer:01,dfm}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.2.4}Parallelization and domain decomposition}{40}}
\newlabel{section:parallel}{{9.2.4}{40}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Domain decomposition for $T_0=10\tmspace  +\thinmuskip {.1667em}{\rm  s}$ and four (left), eight (middle), and sixteen (right two panels) processors. Note that each processor has the same number of elements (``efficiency''), and maximally two neighbors (minimal latency) with small shared boundaries (i.e., small bandwidth). Each processor touches the axis, albeit to varying amounts. Axial terms are however 1-D, and as such do not add any countable CPU time to the overall scheme.The central region is subdivided such that each processor has exactly the same amount of elements.}}{41}}
\newlabel{img:dd}{{17}{41}}
\citation{dfm}
\citation{karniadakis}
\citation{KoVi98}
\citation{KoTr99}
\citation{KoTr02a}
\citation{manu03}
\citation{Chaljub+:06}
\citation{bernardi}
\citation{fournier04}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Relative simulation times of the time loop for different numbers of processors $N_{\rm  proc}$, either keeping the total memory (i.e., constant mesh and resolution) or the per-processor memory constant (i.e., constant job load per processor). $t_0$ is the CPU time for the one-processor case; the diagonal constitutes the case for which CPU times are unaffected by the parallelization. In both our cases, the parallelization plays such a minor role that simulation times are actually \textit  {shorter} for more processors, adhering to smaller memory occupation and negligible parallel communication patterns.}}{42}}
\newlabel{img:scaling}{{18}{42}}
\citation{KoTr02a}
\citation{manuthesis}
\citation{fournier04}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces The sum over all message sizes versus total volume size (both counted in unique grid points) for each mesh and $N_{\rm  proc}$, i.e. the grid fraction that communicates. If this function reaches a significantly large value, then the parallelization and message passing will take up larger fractions of the CPU time, but as our case indicates, it shall asymptotically approach value below $1\tmspace  +\thinmuskip {.1667em}\%$ for all projected, feasible cases of up to $32$ processors. }}{43}}
\newlabel{img:message_surf_vol}{{19}{43}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.3}Spectral-element discretization}{43}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.3.1}Geometrical mapping and discretization}{43}}
\newlabel{section:geometrical}{{9.3.1}{43}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces The mesh architecture. The geometric mapping mentioned in Section~\ref  {section:geometrical} transforms the unit square element (A), within which all computations are undertaken, into any quadrilateral element $\Omega _e$ or $\mathaccentV {bar}016{\Omega }_e$ (B). (C) shows the actual mesh used in the simulations described in Section~\ref  {section:validation}. Three different element geometries, as defined in Appendix~\ref  {appsection:geom_mapping} and Fig.~\ref  {figa1}, are used to construct this mesh such that spacing variations are kept small. The radius of the earth is $r_0$, and the left straight edge is the non-physical axis of symmetry for which we employ different discretization rules due to the appearance of singularities $s^{-1}$.}}{44}}
\newlabel{fig1}{{20}{44}}
\newlabel{eq:jacob}{{17}{44}}
\newlabel{eq:ds_u}{{18}{44}}
\citation{dfm}
\newlabel{eq:dz_u}{{19}{45}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.3.2}General non-axial functional discretization}{45}}
\newlabel{section:nonax}{{9.3.2}{45}}
\newlabel{eq:gll_quad_nonax}{{20}{45}}
\newlabel{eq:u_pol}{{21}{45}}
\newlabel{eq:w_pol}{{22}{45}}
\citation{fournier05,bernardi}
\newlabel{eq:discrete_deriv}{{23}{46}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.3.3}Gauss-Lobatto-Jacobi (0,1) quadrature in axial elements}{46}}
\newlabel{section:ax}{{9.3.3}{46}}
\newlabel{eq:glj_quad_ax}{{25}{46}}
\citation{fournier04}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.3.4}Geometrical mapping}{47}}
\newlabel{appsection:geom_mapping}{{9.3.4}{47}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Elemental shapes. Sketch illustrating the three fundamental element-shape geometries used to construct the mesh. The mesh on the left is a low resolution example to simply highlight the skeleton. (A) is the analytically expressed circular element shape, (B) is the purely rectangular element shape necessary to mesh the central part of the domain and computed in a subparametric fashion (``serendipity quadrilateral''), and (C) is the connecting type between (A) and (B), mapped using an analytical formula similar to type (A). Both (A) and (C) take on two different shapes, one of which is located within the coarsening region, respectively. Numbers denote the collocation point indices as used in Appendix~\ref  {appsection:geom_mapping}.}}{47}}
\newlabel{figa1}{{21}{47}}
\newlabel{appeq:generic_sz_a_c}{{27}{47}}
\citation{KoTr99}
\citation{hughes}
\newlabel{appeq:sz_top_ac}{{28}{48}}
\newlabel{appeq:sz_bot_a}{{29}{48}}
\newlabel{appeq:sz_bot_c}{{30}{48}}
\newlabel{appeq:serend_shp8_1}{{32}{48}}
\newlabel{appeq:serend_shp8_8}{{39}{48}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.3.5}Gauss-Lobatto-Legendre quadrature}{48}}
\newlabel{appsection:gll}{{9.3.5}{48}}
\newlabel{appeq:legendre_ode}{{40}{48}}
\newlabel{appeq:legendrepol}{{41}{48}}
\citation{fournierthesis}
\citation{bernardi}
\citation{karniadakis}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.3.6}Gauss-Lobatto-Jacobi (0,1) quadrature}{49}}
\newlabel{appsection:glj_ax}{{9.3.6}{49}}
\newlabel{appeq:jacobi_ode}{{48}{49}}
\citation{fournierthesis}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.3.7}Discretized equations of motion}{50}}
\newlabel{section:discr_eq_motion}{{9.3.7}{50}}
\citation{nissen+:07a,fournier04,bernardi}
\citation{dfm}
\citation{dfm}
\newlabel{eq:ode}{{54}{51}}
\newlabel{eq:stiff_el_glob}{{56}{51}}
\newlabel{eq:global_ode}{{57}{51}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.3.8}Source terms}{51}}
\newlabel{section:source}{{9.3.8}{51}}
\newlabel{eq:src_mo}{{58}{52}}
\newlabel{eq:src_di}{{61}{52}}
\newlabel{eq:src_qu}{{64}{52}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.3.9}Mass terms}{52}}
\newlabel{section:mass}{{9.3.9}{52}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Moment-tensor source gallery. Due to the polynomial representation of functions in the spectral-element method, a point-like moment-tensor source, containing $\unhbox \voidb@x \hbox {\relax \mathversion  {bold}$\bf  \nabla $}\mathbf  {w}$, spreads out over the bearing element in its discretized form. The figure shows all non-zero source vector components $\mathbf  {f}_\beta $ as defined in eqs~(\ref  {eq:src_mo})--(\ref  {eq:src_qu}) for the element containing the source at polynomial order $N=8$. Arrow lengths represent the relative values of the magnitude of $\mathbf  {f}_\beta $. The physical source location on the axis $s=0$ is denoted by a large black dot. Neighboring elements (not shown) share the same values as the edge of the shown element, thus a maximum of four elements may have non-zero source terms. Note that the location and relative spacing of grid points within the element is different for directions parallel and perpendicular to the axis, reflecting the axial discretization in terms of GLJ points for the $\xi $ (and $s$) directions, and GLL points for the $\eta $ (and $z$) directions (see Sections~\ref  {section:nonax},~\ref  {section:ax} and Appendices~\ref  {appsection:gll},~\ref  {appsection:glj_ax}).}}{53}}
\newlabel{fig2}{{22}{53}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.3.10}Stiffness terms}{53}}
\newlabel{section:stiffness}{{9.3.10}{53}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Definitions for precomputable matrices of the stiffness term ($\epsilon =\lambda ,~\mu $ or any combination thereof).}}{54}}
\newlabel{table:precomp}{{3}{54}}
\newlabel{eq:scheme_wu}{{68}{54}}
\newlabel{eq:scheme_wdu}{{69}{54}}
\newlabel{eq:scheme_dwu}{{70}{54}}
\newlabel{eq:scheme_dwdu}{{71}{54}}
\newlabel{eq:scheme_wu_ax}{{72}{55}}
\newlabel{eq:scheme_wdu_ax}{{73}{55}}
\newlabel{eq:scheme_dwu_ax}{{74}{55}}
\newlabel{eq:scheme_dwdu_ax}{{75}{55}}
\newlabel{eq:stiff_add_ax_s}{{76}{55}}
\newlabel{eq:stiff_add_ax_z1}{{77}{55}}
\newlabel{eq:stiff_add_ax_z2}{{78}{55}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Definitions of tensor notations and product operations, based on definitions in Table~\ref  {table:precomp}. }}{56}}
\newlabel{apptable:matrix_op}{{4}{56}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.3.11}Matrix notation, tensor products and recast stiffness system}{56}}
\newlabel{appsection:stiffness_mxm}{{9.3.11}{56}}
\newlabel{appeq:R1}{{79}{56}}
\newlabel{appeq:R2}{{80}{56}}
\newlabel{appeq:R3}{{81}{56}}
\newlabel{appeq:R4}{{82}{56}}
\citation{dfm}
\newlabel{appeq:R1ax}{{83}{57}}
\newlabel{appeq:R2ax}{{84}{57}}
\newlabel{appeq:R3ax}{{85}{57}}
\newlabel{appeq:R4ax}{{86}{57}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.3.12}Leading order terms}{57}}
\newlabel{eq:stiff_4th_sums}{{93}{58}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.3.13}Lower order terms: monopole}{58}}
\newlabel{appeq:loword_monos}{{96}{58}}
\newlabel{appeq:loword_monoz}{{97}{58}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.3.14}Lower order terms: dipole}{58}}
\newlabel{RF1}{59}
\newlabel{apptable:precomp_E}{{9.3.12}{59}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.3.15}Lower order terms: quadrupole}{60}}
\newlabel{appeq:loword_quads}{{104}{60}}
\newlabel{appeq:loword_quadphi}{{105}{60}}
\newlabel{appeq:loword_quadz}{{106}{60}}
\citation{nissen+:07b}
\citation{nissen+:07b}
\citation{nissen+:07b}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.3.16}Fluid mass and stiffness terms}{61}}
\newlabel{eq:scheme_dwdu}{{111}{61}}
\citation{nissen+:07b}
\citation{nissen+:07b}
\newlabel{eq:scheme_wu_nonax}{{112}{62}}
\newlabel{eq:scheme_wu_ax}{{113}{62}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Sketch to illustrate our nomenclature around a solid-fluid boundary (in this case CMB). $r_{\rm  sf}$ is the radius, and $\Sigma _{\rm  f}^{\rm  s}$ the surface of the boundary. $(.,.)$ denote the respective elemental indices $(I,J)$ of Gauss-Lobatto-Legendre points of the boundary-hugging corner points of elements above and below.}}{62}}
\newlabel{img:bdry}{{23}{62}}
\citation{nissen+:07b}
\citation{nissen+:07b}
\citation{KoVi98}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.3.17}Solid-fluid coupling terms}{63}}
\newlabel{eq:boundary_solid}{{114}{63}}
\newlabel{eq:boundary_fluid}{{115}{63}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.4}Time marching}{63}}
\newlabel{eq:global_ode}{{116}{63}}
\newlabel{eq:global_ode1}{{116}{63}}
\newlabel{eq:global_ode2}{{117}{63}}
\newlabel{eq:global_ode3}{{118}{63}}
\citation{nissen+:07b}
\citation{manu03}
\citation{Ampuero+:07}
\citation{omelyan+:02}
\citation{omelyan+:03}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.4.1}Second-order Newmark scheme}{64}}
\newlabel{eq:newmark1}{{119}{64}}
\newlabel{eq:newmark2}{{120}{64}}
\newlabel{eq:newmark3}{{121}{64}}
\newlabel{eq:newmark4}{{122}{64}}
\newlabel{eq:newmark5}{{123}{64}}
\newlabel{eq:newmark6}{{124}{64}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.4.2}Fourth-order symplectic scheme}{64}}
\newlabel{section:symplectic}{{9.4.2}{64}}
\newlabel{eq:pefrl}{{125}{64}}
\citation{Ampuero+:07}
\citation{nissen+:07b}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.5}On-the-fly accuracy tests}{65}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.5.1}Surfaces, volumes, and masses}{65}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Accuracy of spherical surfaces ${\EuScript  S}$, volumes ${\EuScript  V}$, and masses ${\EuScript  M}$ for different mesh resolutions.}}{66}}
\newlabel{table:surfvol}{{5}{66}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.5.2}Discrete material property variations}{66}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Material property variations across elements.}}{66}}
\newlabel{table:material_across_elements}{{6}{66}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.5.3}Resolution trigonometry}{67}}
\newlabel{table:resol_sine}{{9.5.3}{67}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Radial sine function accuracy for various resolutions.}}{67}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.5.4}Run-time breakdown}{67}}
\newlabel{appsection:runtime_breakdown}{{9.5.4}{67}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces Fractional simulation times for the various subprocesses such as stiffness summation, message passing, assembly, and output of seismograms as a function of number of processors. $t_0$ denotes the simulation time using only one processor.}}{68}}
\newlabel{img:frac_runtimes}{{24}{68}}
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces Fractional run-times for several simulation types at $T_0=10\tmspace  +\thinmuskip {.1667em} \textrm  {s}$ for $1900$ time steps.}}{68}}
\newlabel{table:runtimes}{{8}{68}}
